{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crash look at UK road traffic accident data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Data Processing\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modelling\n",
    "from sklearn.neighbors import KDTree, NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN, OPTICS\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Visualisation Packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read up accidents\n",
    "accidents_2019 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/DfTRoadSafety_Accidents_2019.zip\",low_memory=False, compression='zip')\n",
    "accidents_2018 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/dftRoadSafetyData_Accidents_2018.csv\",low_memory=False)\n",
    "accidents_2017 = pd.read_csv(r\"http://data.dft.gov.uk.s3.amazonaws.com/road-accidents-safety-data/dftRoadSafetyData_Accidents_2017.zip\",low_memory=False, compression='zip')\n",
    "accidents_2016 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/dftRoadSafety_Accidents_2016.zip\",low_memory=False, compression='zip')\n",
    "accidents_2015 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/RoadSafetyData_Accidents_2015.zip\",low_memory=False, compression='zip')\n",
    "accidents_2014 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/DfTRoadSafety_Accidents_2014.zip\",low_memory=False)\n",
    "\n",
    "# Read up casualties\n",
    "casualties_2019 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/DfTRoadSafety_Casualties_2019.zip\",low_memory=False, compression='zip')\n",
    "casualties_2018 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/dftRoadSafetyData_Casualties_2018.csv\",low_memory=False)\n",
    "casualties_2017 = pd.read_csv(r\"http://data.dft.gov.uk.s3.amazonaws.com/road-accidents-safety-data/dftRoadSafetyData_Casualties_2017.zip\",low_memory=False, compression='zip')\n",
    "casualties_2016 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/dftRoadSafetyData_Casualties_2016.zip\",low_memory=False, compression='zip')\n",
    "casualties_2015 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/RoadSafetyData_Casualties_2015.zip\",low_memory=False, compression='zip')\n",
    "casualties_2014 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/DfTRoadSafety_Casualties_2014.zip\",low_memory=False, compression='zip')\n",
    "\n",
    "# Read up vehicles\n",
    "vehicles_2019 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/DfTRoadSafety_Vehicles_2019.zip\",low_memory=False, compression='zip')\n",
    "vehicles_2018 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/dftRoadSafetyData_Vehicles_2018.csv\",low_memory=False)\n",
    "vehicles_2017 = pd.read_csv(r\"http://data.dft.gov.uk.s3.amazonaws.com/road-accidents-safety-data/dftRoadSafetyData_Vehicles_2017.zip\",low_memory=False, compression='zip')\n",
    "vehicles_2016 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/dftRoadSafetyData_Vehicles_2016.zip\",low_memory=False, compression='zip')\n",
    "vehicles_2015 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/RoadSafetyData_Vehicles_2015.zip\",low_memory=False, compression='zip')\n",
    "vehicles_2014 = pd.read_csv(r\"http://data.dft.gov.uk/road-accidents-safety-data/DfTRoadSafety_Vehicles_2014.zip\",low_memory=False, compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single dataframe\n",
    "df_accidents = accidents_2019.append([accidents_2018, accidents_2017, accidents_2016, accidents_2015], sort=False)\n",
    "df_vehicles = vehicles_2019.append([vehicles_2018, vehicles_2017, vehicles_2016, vehicles_2015], sort=False)\n",
    "df_casualties = casualties_2019.append([casualties_2018, casualties_2017, casualties_2016, casualties_2015], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646830\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accident_Index</th>\n",
       "      <th>Location_Easting_OSGR</th>\n",
       "      <th>Location_Northing_OSGR</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Police_Force</th>\n",
       "      <th>Accident_Severity</th>\n",
       "      <th>Number_of_Vehicles</th>\n",
       "      <th>Number_of_Casualties</th>\n",
       "      <th>Date</th>\n",
       "      <th>...</th>\n",
       "      <th>Pedestrian_Crossing-Human_Control</th>\n",
       "      <th>Pedestrian_Crossing-Physical_Facilities</th>\n",
       "      <th>Light_Conditions</th>\n",
       "      <th>Weather_Conditions</th>\n",
       "      <th>Road_Surface_Conditions</th>\n",
       "      <th>Special_Conditions_at_Site</th>\n",
       "      <th>Carriageway_Hazards</th>\n",
       "      <th>Urban_or_Rural_Area</th>\n",
       "      <th>Did_Police_Officer_Attend_Scene_of_Accident</th>\n",
       "      <th>LSOA_of_Accident_Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019010128300</td>\n",
       "      <td>528218.0</td>\n",
       "      <td>180407.0</td>\n",
       "      <td>-0.153842</td>\n",
       "      <td>51.508057</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18/02/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>E01004762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019010152270</td>\n",
       "      <td>530219.0</td>\n",
       "      <td>172463.0</td>\n",
       "      <td>-0.127949</td>\n",
       "      <td>51.436208</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15/01/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>E01003117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019010155191</td>\n",
       "      <td>530222.0</td>\n",
       "      <td>182543.0</td>\n",
       "      <td>-0.124193</td>\n",
       "      <td>51.526795</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E01000943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accident_Index  Location_Easting_OSGR  Location_Northing_OSGR  Longitude  \\\n",
       "0  2019010128300               528218.0                180407.0  -0.153842   \n",
       "1  2019010152270               530219.0                172463.0  -0.127949   \n",
       "2  2019010155191               530222.0                182543.0  -0.124193   \n",
       "\n",
       "    Latitude  Police_Force  Accident_Severity  Number_of_Vehicles  \\\n",
       "0  51.508057             1                  3                   2   \n",
       "1  51.436208             1                  3                   2   \n",
       "2  51.526795             1                  3                   2   \n",
       "\n",
       "   Number_of_Casualties        Date  ...  Pedestrian_Crossing-Human_Control  \\\n",
       "0                     3  18/02/2019  ...                                  0   \n",
       "1                     1  15/01/2019  ...                                 -1   \n",
       "2                     1  01/01/2019  ...                                  0   \n",
       "\n",
       "  Pedestrian_Crossing-Physical_Facilities  Light_Conditions  \\\n",
       "0                                       5                 1   \n",
       "1                                      -1                 4   \n",
       "2                                       0                 4   \n",
       "\n",
       "  Weather_Conditions  Road_Surface_Conditions  Special_Conditions_at_Site  \\\n",
       "0                  1                        1                           0   \n",
       "1                  1                        1                           0   \n",
       "2                  1                        1                           0   \n",
       "\n",
       "   Carriageway_Hazards  Urban_or_Rural_Area  \\\n",
       "0                    0                    1   \n",
       "1                    0                    1   \n",
       "2                    0                    1   \n",
       "\n",
       "   Did_Police_Officer_Attend_Scene_of_Accident  LSOA_of_Accident_Location  \n",
       "0                                            3                  E01004762  \n",
       "1                                            3                  E01003117  \n",
       "2                                            1                  E01000943  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_accidents))\n",
    "df_accidents.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Accident_Index', 'Location_Easting_OSGR', 'Location_Northing_OSGR',\n",
       "       'Longitude', 'Latitude', 'Police_Force', 'Accident_Severity',\n",
       "       'Number_of_Vehicles', 'Number_of_Casualties', 'Date', 'Day_of_Week',\n",
       "       'Time', 'Local_Authority_(District)', 'Local_Authority_(Highway)',\n",
       "       '1st_Road_Class', '1st_Road_Number', 'Road_Type', 'Speed_limit',\n",
       "       'Junction_Detail', 'Junction_Control', '2nd_Road_Class',\n",
       "       '2nd_Road_Number', 'Pedestrian_Crossing-Human_Control',\n",
       "       'Pedestrian_Crossing-Physical_Facilities', 'Light_Conditions',\n",
       "       'Weather_Conditions', 'Road_Surface_Conditions',\n",
       "       'Special_Conditions_at_Site', 'Carriageway_Hazards',\n",
       "       'Urban_or_Rural_Area', 'Did_Police_Officer_Attend_Scene_of_Accident',\n",
       "       'LSOA_of_Accident_Location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents_2019.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1192061\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accident_Index</th>\n",
       "      <th>Vehicle_Reference</th>\n",
       "      <th>Vehicle_Type</th>\n",
       "      <th>Towing_and_Articulation</th>\n",
       "      <th>Vehicle_Manoeuvre</th>\n",
       "      <th>Vehicle_Location-Restricted_Lane</th>\n",
       "      <th>Junction_Location</th>\n",
       "      <th>Skidding_and_Overturning</th>\n",
       "      <th>Hit_Object_in_Carriageway</th>\n",
       "      <th>Vehicle_Leaving_Carriageway</th>\n",
       "      <th>...</th>\n",
       "      <th>Journey_Purpose_of_Driver</th>\n",
       "      <th>Sex_of_Driver</th>\n",
       "      <th>Age_of_Driver</th>\n",
       "      <th>Age_Band_of_Driver</th>\n",
       "      <th>Engine_Capacity_(CC)</th>\n",
       "      <th>Propulsion_Code</th>\n",
       "      <th>Age_of_Vehicle</th>\n",
       "      <th>Driver_IMD_Decile</th>\n",
       "      <th>Driver_Home_Area_Type</th>\n",
       "      <th>Vehicle_IMD_Decile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019010128300</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019010128300</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019010152270</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accident_Index  Vehicle_Reference  Vehicle_Type  Towing_and_Articulation  \\\n",
       "0  2019010128300                  1             9                        0   \n",
       "1  2019010128300                  2             9                        0   \n",
       "2  2019010152270                  1             9                        0   \n",
       "\n",
       "   Vehicle_Manoeuvre  Vehicle_Location-Restricted_Lane  Junction_Location  \\\n",
       "0                 -1                                -1                 -1   \n",
       "1                 -1                                -1                 -1   \n",
       "2                 18                                -1                  0   \n",
       "\n",
       "   Skidding_and_Overturning  Hit_Object_in_Carriageway  \\\n",
       "0                        -1                         -1   \n",
       "1                        -1                         -1   \n",
       "2                        -1                         -1   \n",
       "\n",
       "   Vehicle_Leaving_Carriageway  ...  Journey_Purpose_of_Driver  Sex_of_Driver  \\\n",
       "0                           -1  ...                          6              1   \n",
       "1                           -1  ...                          6              3   \n",
       "2                           -1  ...                          6              2   \n",
       "\n",
       "   Age_of_Driver  Age_Band_of_Driver  Engine_Capacity_(CC)  Propulsion_Code  \\\n",
       "0             58                   9                    -1               -1   \n",
       "1             -1                  -1                    -1               -1   \n",
       "2             24                   5                    -1               -1   \n",
       "\n",
       "   Age_of_Vehicle  Driver_IMD_Decile  Driver_Home_Area_Type  \\\n",
       "0              -1                  2                      1   \n",
       "1              -1                  2                      1   \n",
       "2              -1                  3                      1   \n",
       "\n",
       "   Vehicle_IMD_Decile  \n",
       "0                   2  \n",
       "1                   2  \n",
       "2                   3  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_vehicles))\n",
    "df_vehicles.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852321\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accident_Index</th>\n",
       "      <th>Vehicle_Reference</th>\n",
       "      <th>Casualty_Reference</th>\n",
       "      <th>Casualty_Class</th>\n",
       "      <th>Sex_of_Casualty</th>\n",
       "      <th>Age_of_Casualty</th>\n",
       "      <th>Age_Band_of_Casualty</th>\n",
       "      <th>Casualty_Severity</th>\n",
       "      <th>Pedestrian_Location</th>\n",
       "      <th>Pedestrian_Movement</th>\n",
       "      <th>Car_Passenger</th>\n",
       "      <th>Bus_or_Coach_Passenger</th>\n",
       "      <th>Pedestrian_Road_Maintenance_Worker</th>\n",
       "      <th>Casualty_Type</th>\n",
       "      <th>Casualty_Home_Area_Type</th>\n",
       "      <th>Casualty_IMD_Decile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019010128300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019010128300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019010128300</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accident_Index  Vehicle_Reference  Casualty_Reference  Casualty_Class  \\\n",
       "0  2019010128300                  1                   1               1   \n",
       "1  2019010128300                  1                   2               2   \n",
       "2  2019010128300                  1                   3               2   \n",
       "\n",
       "   Sex_of_Casualty  Age_of_Casualty  Age_Band_of_Casualty  Casualty_Severity  \\\n",
       "0                1               58                     9                  3   \n",
       "1                2               -1                    -1                  3   \n",
       "2                2               -1                    -1                  3   \n",
       "\n",
       "   Pedestrian_Location  Pedestrian_Movement  Car_Passenger  \\\n",
       "0                    0                    0              0   \n",
       "1                    0                    0              1   \n",
       "2                    0                    0              2   \n",
       "\n",
       "   Bus_or_Coach_Passenger  Pedestrian_Road_Maintenance_Worker  Casualty_Type  \\\n",
       "0                       0                                   0              9   \n",
       "1                       0                                   0              9   \n",
       "2                       0                                   0              9   \n",
       "\n",
       "   Casualty_Home_Area_Type  Casualty_IMD_Decile  \n",
       "0                        1                    2  \n",
       "1                        1                    5  \n",
       "2                        1                    5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_casualties))\n",
    "df_casualties.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data\n",
    " - Keep columns needed\n",
    " - Convert date to DateTime\n",
    " - check the number of missing or \"out of range values\"\n",
    " - Convert the default encoding to Pandas Categorical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToCategorical(df, col_name_list, category_dict_list):\n",
    "    '''\n",
    "    Converts the given columns to categorical data type with the correct categories\n",
    "    used from the category_dict_list\n",
    "    \n",
    "    Parameters:\n",
    "    df (Pandas DataFrame): Input dataframe with columns to convert to categorical type\n",
    "    col_name_list  (list): List of column names from df. These columns will be converted\n",
    "    category_dict_list (list): a list of dictionaries. each dictioanry corresponds to the respective column\n",
    "       and holds the correct category names to use.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with categorical columns \n",
    "    '''\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    \n",
    "    for i,col in enumerate(col_name_list):\n",
    "        df_out[col] = df_out[col].astype('category')\n",
    "        df_out[col].cat.categories = [category_dict_list[i][j] for j in df_out[col].cat.categories]\n",
    "        \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep columns used, remove other columns\n",
    "accident_cols_to_keep= ['Accident_Index', 'Location_Easting_OSGR', 'Location_Northing_OSGR',\n",
    "                        'Longitude', 'Latitude','Date','1st_Road_Class','Speed_limit',\n",
    "                        'Light_Conditions','Weather_Conditions', 'Road_Surface_Conditions']\n",
    "\n",
    "vehicle_cols_to_keep = ['Accident_Index', 'Vehicle_Reference', 'Vehicle_Type', 'Age_of_Driver', 'Sex_of_Driver']\n",
    "\n",
    "casuality_cols_to_keep = ['Accident_Index', 'Vehicle_Reference', 'Casualty_Reference',\n",
    "                          'Casualty_Severity']\n",
    "\n",
    "\n",
    "df_accidents = df_accidents[accident_cols_to_keep].copy()\n",
    "df_vehicles = df_vehicles[vehicle_cols_to_keep].copy()\n",
    "df_casualties = df_casualties[casuality_cols_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in Date column: 0\n"
     ]
    }
   ],
   "source": [
    "# convert Date to DateTime object (Time is missing from ~100 accidents)\n",
    "print('Number of null values in Date column: ' + str(len(df_accidents[df_accidents[[\"Date\"]].isnull().any(axis=1)])))\n",
    "df_accidents[\"Date\"] = pd.DatetimeIndex(df_accidents[\"Date\"], dayfirst=True)\n",
    "df_accidents[\"Year\"] = df_accidents[\"Date\"].dt.year.astype('Int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c0da74bbd452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m df_accidents = ToCategorical(df_accidents,\n\u001b[0m\u001b[1;32m     16\u001b[0m                              \u001b[0;34m[\u001b[0m\u001b[0;34m'1st_Road_Class'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Speed_limit'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Light_Conditions'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Weather_Conditions'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Road_Surface_Conditions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                              [road_class_dict,light_dict,weather_dict,surface_dict])\n",
      "\u001b[0;32m<ipython-input-8-c216be69a5ca>\u001b[0m in \u001b[0;36mToCategorical\u001b[0;34m(df, col_name_list, category_dict_list)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_name_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcategory_dict_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c216be69a5ca>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_name_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcategory_dict_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0.0"
     ]
    }
   ],
   "source": [
    "# Map categories\n",
    "gender_dict = {1:'Male',2:'Female', 3:'Not known', -1:'Data missing or out of range'}\n",
    "light_dict = {1:'Daylight',4:'Darkness - lights lit',5:'Darkness - lights unlit',6:'Darkness - no lighting',7:'Darkness - lighting unknown',-1:'Data missing or out of range'}\n",
    "weather_dict ={1:'Fine no high winds',2:'Raining no high winds',3:'Snowing no high winds',4:'Fine + high winds',5:'Raining + high winds',6:'Snowing + high winds',7:'Fog or mist',8:'Other',9:'Unknown',-1:'Data missing or out of range'}\n",
    "surface_dict = {1:'Dry',2:'Wet or damp',3:'Snow',4:'Frost or ice',5:'Flood over 3cm. deep',6:'Oil or diesel',7:'Mud',-1:'Data missing or out of range'}\n",
    "severity_dict = {1:'Fatal',2:'Serious',3:'Slight'}\n",
    "speed_limit = {20:'20 MPH', 30:'30 MPH', 40:'40 MPH', 50:'50 MPH', 60:'60 MPH', 70:'70 MPH', -1:'Data missing or out of range'}\n",
    "vehicle_type_dict = {1:'Pedal cycle', 2:'Motorcycle 50cc and under', 3:'Motorcycle 125cc and under', 4:'Motorcycle over 125cc and up to 500cc', 5:'Motorcycle over 500cc', 8:'Taxi/Private hire car', 9:'Car', 10:'Minibus (8 - 16 passenger seats)',\n",
    "                     11:'Bus or coach (17 or more pass seats)', 16:'Ridden horse', 17:'Agricultural vehicle', 18:'Tram', 19:'Van / Goods 3.5 tonnes mgw or under', 20:'Goods over 3.5t. and under 7.5t', 21:'Goods 7.5 tonnes mgw and over', 22:'Mobility scooter',\n",
    "                     23:'Electric motorcycle', 90:'Other vehicle', 97:'Motorcycle - unknown cc', 98:'Goods vehicle - unknown weight', -1:'Data missing or out of range',}\n",
    "\n",
    "road_class_dict = {1:'Motorway', 2:'A(M)', 3:'A', 4:'B', 5:'C', 6:'Unclassified'}\n",
    "\n",
    "\n",
    "df_accidents = ToCategorical(df_accidents,\n",
    "                             ['1st_Road_Class','Speed_limit','Light_Conditions','Weather_Conditions','Road_Surface_Conditions'],\n",
    "                             [road_class_dict,light_dict,weather_dict,surface_dict])\n",
    "\n",
    "df_vehicles = ToCategorical(df_vehicles, ['Vehicle_Type', 'Sex_of_Driver'], [vehicle_type_dict, gender_dict])\n",
    "df_casualties = ToCategorical(df_casualties, ['Casualty_Severity'], [severity_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of missing values\n",
    "\n",
    "def CheckNulls(df, df_name='DataFrame'):\n",
    "    '''\n",
    "    Function that checks the number of rows with any missing values\n",
    "    Input:\n",
    "    df: DataFrame to check\n",
    "    df_name: str, name to use as DF name in the returned prints\n",
    "    \n",
    "    Returns: Null, printing the numbor missig rows to the screen\n",
    "    '''\n",
    "    print('\\n'+df_name)\n",
    "    # Total number of Accident Table\n",
    "    print(f'Number of rows in {df_name}: \\t{len(df)}')\n",
    "\n",
    "    # Numeric columns\n",
    "    print(f'Number of numerical rows with any missing values in {df_name}: {df.isnull().any(axis=1).sum()}')\n",
    "    cols_w_null = df.columns[df.isnull().any()].to_list()\n",
    "    print(f'Numeric columns with nulls: {cols_w_null}')\n",
    "    \n",
    "    # Categoorical columns\n",
    "    missing_cat_rows = df.isin(['Data missing or out of range','Unknown']).any(axis=1).sum()\n",
    "    print(f'Number of categorical rows with any missing values in {df_name}: {missing_cat_rows}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accidents\n",
    "CheckNulls(df_accidents, 'df_accidents')\n",
    "CheckNulls(df_vehicles, 'df_vehicles')\n",
    "CheckNulls(df_casualties, 'df_casualties')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Note:</b> Although the number of rows with missing values seems small compared to the total sample size, they will be dealt with on a case-by-case basis, removing the missing values based on the columns used for the specific \n",
    "    analysis only.<br>\n",
    "    E.g. We can still use rows for finding hot spots if driver age is not recorded (but coordinates are available). </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Is transport becoming safer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Date to casualities\n",
    "df_casualties_date = df_casualties.merge(df_accidents[[\"Accident_Index\",\"Year\"]], left_on=\"Accident_Index\",right_on=\"Accident_Index\",how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count accidents by year\n",
    "df_accidents_by_year = df_accidents[\"Year\"].value_counts()\n",
    "\n",
    "# Plot\n",
    "ax = sns.barplot(y=df_accidents_by_year.values, x=df_accidents_by_year.index, palette=\"Blues_d\")\n",
    "ax.set(xlabel=\"Year\", ylabel = \"Number of Accidents\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the number of casualities change\n",
    "df_casualties_by_year = df_casualties_date.groupby(by=['Casualty_Severity','Year'], as_index=False)['Accident_Index'].count()\n",
    "df_total_casualities = df_casualties_by_year.groupby(by='Year', as_index=False)['Accident_Index'].sum()\n",
    "df_total_casualities['Casualty_Severity'] = 'All Casualities'\n",
    "\n",
    "df_casualties_by_year = df_casualties_by_year.append(df_total_casualities)\n",
    "\n",
    "g = sns.FacetGrid(df_casualties_by_year, col=\"Casualty_Severity\", sharey=False, height=4,\n",
    "    aspect=1.2,)\n",
    "g.map(sns.barplot, \"Year\", \"Accident_Index\", order=[2015,2016,2017,2018,2019])\n",
    "g.set_axis_labels(y_var='Number of Casualities')\n",
    "g.set_titles(col_template = '{col_name}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage change compared to 2015 baseline\n",
    "df_casualties_change_by_year = df_casualties_by_year.copy()\n",
    "\n",
    "baseline = df_casualties_by_year.loc[df_casualties_by_year['Year']==2015,:]\n",
    "\n",
    "for segment in df_casualties_by_year['Casualty_Severity'].unique():\n",
    "    this_segment = df_casualties_change_by_year['Casualty_Severity']==segment\n",
    "    this_baseline= baseline.loc[baseline['Casualty_Severity']==segment, 'Accident_Index'].values\n",
    "    \n",
    "    df_casualties_change_by_year.loc[this_segment, 'Accident_Index'] = df_casualties_change_by_year.loc[this_segment, 'Accident_Index']/this_baseline * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.relplot(x=\"Year\", y=\"Accident_Index\", style=\"Casualty_Severity\",\n",
    "            palette=\"Blues_d\",\n",
    "            kind=\"line\",\n",
    "            data=df_casualties_change_by_year);\n",
    "\n",
    "fig.set(ylim=(0, 120), xticks=[2015,2016,2017,2018,2019], ylabel='% Change in Number of Casualities');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Are young drivers involved in more accidents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop records with missing age of driver\n",
    "df_vehicles_age = df_vehicles[df_vehicles['Age_of_Driver']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.1)\n",
    "sns.set_style(\"white\")\n",
    "fig = sns.displot(df_vehicles_age, x='Age_of_Driver', kind='hist', bins=list(range(0,110,5)), kde=True,\n",
    "              height=4, aspect=2)\n",
    "fig.set(xlim=(0, 110), xlabel=('Age'), xticks=list(range(0,110,10)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Are female drivers involved in more accidents then men?\n",
    "\n",
    "https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/905926/nts0206.ods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing or unkown values\n",
    "df_vehicles_age_gender = df_vehicles_age[df_vehicles_age['Sex_of_Driver'].isin(['Male', 'Female'])]\n",
    "df_vehicles_age_gender['Sex_of_Driver'].cat.remove_unused_categories(inplace=True)\n",
    "\n",
    "df_vehicles_age_gender['Sex_of_Driver'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Plot\n",
    "fig = sns.catplot(x=\"Sex_of_Driver\", kind=\"count\", data=df_vehicles_age_gender)\n",
    "fig.set_xlabels('Gender of Driver') # , fontsize=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.displot(df_vehicles_age_gender, x='Age_of_Driver', hue='Sex_of_Driver',\n",
    "                  kind='hist', bins=list(range(0,110,5)), kde=True, height=4, aspect=2)\n",
    "fig.set(xlim=(0, 110), xlabel=('Age'), xticks=list(range(0,110,10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a are any vehicles types more dangerous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs vehicle type\n",
    "df_vehicles\n",
    "\n",
    "df_casualties_vehicles = df_casualties.merge(df_vehicles[['Accident_Index', 'Vehicle_Reference', 'Vehicle_Type']], on=['Accident_Index', 'Vehicle_Reference'], how='left')\n",
    "df_casualties_vehicles_roadtype = df_casualties_vehicles.merge(df_accidents[['Accident_Index', '1st_Road_Class']], on=['Accident_Index'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "print(len(df_casualties_vehicles_roadtype))\n",
    "df_casualties_vehicles_roadtype = df_casualties_vehicles_roadtype[~(df_casualties_vehicles_roadtype[['Vehicle_Type','1st_Road_Class']].isin(['Data missing or out of range','Unkown']).any(axis=1))].copy()\n",
    "print(len(df_casualties_vehicles_roadtype))\n",
    "\n",
    "# Calculate Killed and severly injured casulty proportions\n",
    "df_ksi_counts = df_casualties_vehicles_roadtype.value_counts(subset=['Vehicle_Type', '1st_Road_Class','Casualty_Severity']).unstack()\n",
    "df_ksi_props = df_ksi_counts[['Fatal', 'Serious']].sum(1) / df_ksi_counts.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ksi_by_vehicle_roadtype=df_ksi_props.to_frame().unstack()# .reset_index() #.rename(columns={0:'KSI'})\n",
    "df_ksi_by_vehicle_roadtype.columns=['Motorway','A(M)','A Road','B Road','C Road','Unclassified']\n",
    "df_ksi_by_vehicle_roadtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=0.9)\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.heatmap(df_ksi_by_vehicle_roadtype, annot=True, cmap='rocket_r',fmt='.2f',\n",
    "            square=True, linewidths=.5, ax=ax)\n",
    "\n",
    "ax.set(xlabel='Road Class', ylabel=\"Vehicle Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b Are certain road types more dangerous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a heatmap, one axis will be speed limit,other roadtypes, the values will be KSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Are injuries more severe in certain weather conditions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Accident condition columns to Casuality severities\n",
    "condition_cols = ['Light_Conditions', 'Weather_Conditions', 'Road_Surface_Conditions']\n",
    "df_casualties_conditions = df_casualties.merge(df_accidents[['Accident_Index'] + condition_cols], on='Accident_Index', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "print(len(df_casualties_conditions))\n",
    "df_casualties_conditions = df_casualties_conditions[~(df_casualties_conditions[condition_cols].isin(['Data missing or out of range','Unkown']).any(axis=1))].copy()\n",
    "print(len(df_casualties_conditions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Killed and severly injured casulty proportions\n",
    "df_ksi_counts = df_casualties_conditions.value_counts(subset=condition_cols+['Casualty_Severity']).unstack()\n",
    "df_ksi_props = df_ksi_counts[['Fatal', 'Serious']].sum(1) / df_ksi_counts.sum(axis=1)\n",
    "\n",
    "df_ksi_props = df_ksi_props.to_frame().reset_index()\n",
    "df_ksi_props.rename(columns={0:'KSI'}, inplace=True)\n",
    "df_ksi_props = df_ksi_props.sort_values(by='KSI', ascending=False).reset_index(drop=True)\n",
    "df_ksi_props.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ksi_props['label'] = df_ksi_props[condition_cols].astype('str').agg('; '.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(height=df_ksi_props['KSI'], x=df_ksi_props.index, linewidth=0, width=1.0)\n",
    "\n",
    "# add the mean as a horisontal line and std as dotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = df_ksi_props.loc[df_ksi_props['KSI']>0, 'KSI'].describe()['std']\n",
    "mean =df_ksi_props.loc[df_ksi_props['KSI']>0, 'KSI'].describe()['mean']\n",
    "df_ksi_props_high = df_ksi_props[df_ksi_props['KSI']>=(mean+std)]\n",
    "\n",
    "plt.bar(height=df_ksi_props_high['KSI'], x=df_ksi_props_high['label'] , linewidth=0, width=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ksi_props_encoded = df_ksi_props.copy()\n",
    "\n",
    "for col in condition_cols:\n",
    "    df_ksi_props_encoded[col] = df_ksi_props[col].cat.codes\n",
    "    \n",
    "df_ksi_props_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.parallel_coordinates(df_ksi_props_encoded,\n",
    "                              color=\"KSI\",\n",
    "                              dimensions=\n",
    "                              ['Light_Conditions','Weather_Conditions',\n",
    "                               'Road_Surface_Conditions','KSI'\n",
    "                              ],\n",
    "                              color_continuous_scale=px.colors.diverging.Tealrose,\n",
    "                              color_continuous_midpoint=0.25)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ksi_props_encoded = ['KSI'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1]\n",
    "labels = ['0-0.1', '0.1-0.2', '0.2-0.3', '0.3-0.4','0.4-0.5','0.5+']\n",
    "df_ksi_props['KSI_binned'] = pd.cut(df_ksi_props['KSI'], bins, include_lowest=True, labels=labels)\n",
    "\n",
    "df_ksi_props.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.parallel_categories(df_ksi_props, dimensions=condition_cols + ['KSI_binned'],\n",
    "                             color=\"KSI\",\n",
    "                             color_continuous_scale=px.colors.sequential.Inferno,\n",
    "                             #labels={'sex':'Payer sex', 'smoker':'Smokers at the table', 'day':'Day of week'}\n",
    "                            )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/bcdunbar/datasets/master/parcoords_data.csv\")\n",
    "\n",
    "fig = go.Figure(data=\n",
    "    go.Parcoords(\n",
    "        line = dict(color = df['colorVal'],\n",
    "                   colorscale = 'Electric',\n",
    "                   showscale = True,\n",
    "                   cmin = -4000,\n",
    "                   cmax = -100),\n",
    "        dimensions = list([\n",
    "            dict(range = [32000,227900],\n",
    "                 constraintrange = [100000,150000],\n",
    "                 label = \"Block Height\", values = df['blockHeight']),\n",
    "            dict(range = [0,700000],\n",
    "                 label = 'Block Width', values = df['blockWidth']),\n",
    "            dict(tickvals = [0,0.5,1,2,3],\n",
    "                 ticktext = ['A','AB','B','Y','Z'],\n",
    "                 label = 'Cyclinder Material', values = df['cycMaterial']),\n",
    "            dict(range = [-1,4],\n",
    "                 tickvals = [0,1,2,3],\n",
    "                 label = 'Block Material', values = df['blockMaterial']),\n",
    "            dict(range = [134,3154],\n",
    "                 visible = True,\n",
    "                 label = 'Total Weight', values = df['totalWeight']),\n",
    "            dict(range = [9,19984],\n",
    "                 label = 'Assembly Penalty Wt', values = df['assemblyPW']),\n",
    "            dict(range = [49000,568000],\n",
    "                 label = 'Height st Width', values = df['HstW'])])\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://datavizcatalogue.com/methods/parallel_coordinates.html\n",
    "\n",
    "# https://towardsdatascience.com/parallel-coordinates-plots-6fcfa066dcb3\n",
    "\n",
    "https://dataforvisualization.com/charts/parallel-sets-plot/#:~:text=Definition,higher%20value%20of%20that%20category.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ksi_props[df_ksi_props['KSI']>0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=0.9)\n",
    "df_light_weather = df_ksi_props[df_ksi_props['Road_Surface_Conditions'].isnull()].pivot(values='KSI',\n",
    "                   index='Light_Conditions',\n",
    "                   columns='Weather_Conditions')\n",
    "\n",
    "sns.heatmap(df_light_weather, annot=True, cmap=\"YlGnBu\", vmin=0, vmax=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_light_surface = df_ksi_props[df_ksi_props['Weather_Conditions'].isnull()].pivot(values='KSI',\n",
    "                   index='Light_Conditions',\n",
    "                   columns='Road_Surface_Conditions')\n",
    "\n",
    "sns.heatmap(df_light_surface, annot=True, cmap=\"YlGnBu\", vmin=0, vmax=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_surface = df_ksi_props[df_ksi_props['Light_Conditions'].isnull()].pivot(values='KSI',\n",
    "                   index='Weather_Conditions',\n",
    "                   columns='Road_Surface_Conditions')\n",
    "\n",
    "sns.heatmap(df_weather_surface, annot=True, cmap=\"YlGnBu\", vmin=0, vmax=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. can we find the worst accident hot spot locations?\n",
    "\n",
    "https://towardsdatascience.com/how-to-embed-interactive-charts-on-your-medium-articles-and-website-6987f7b28472#:~:text=Embed%20in%20Medium&text=Using%20Datapane's%20API%2C%20you%20can,and%20embed%20it%20into%20Medium.&text=Once%20you%20have%20logged%20in,single%20Plot%20component%20in%20it.\n",
    "https://andrewpwheeler.com/2015/09/03/using-kdtrees-in-python-to-calculate-neighbor-counts/\n",
    "\n",
    "https://towardsdatascience.com/mapping-the-uks-traffic-accident-hotspots-632b1129057b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Coordinates to casualities\n",
    "casuality_cols = ['Accident_Index','Vehicle_Reference','Casualty_Reference','Casualty_Severity']\n",
    "coordinate_cols = ['Accident_Index','Location_Easting_OSGR', 'Location_Northing_OSGR']\n",
    "df_casualties_coords = df_casualties[casuality_cols].merge(df_accidents[coordinate_cols], on='Accident_Index', how='left')\n",
    "\n",
    "# Drop Slight Injuries\n",
    "print(len(df_casualties_coords))\n",
    "df_casualties_coords = df_casualties_coords[~(df_casualties_coords['Casualty_Severity']=='Slight')].copy()\n",
    "\n",
    "# Drop missing coordinates\n",
    "print(len(df_casualties_coords))\n",
    "df_casualties_coords = df_casualties_coords[~df_casualties_coords[['Location_Easting_OSGR','Location_Northing_OSGR']].isnull().any(axis=1)]\n",
    "\n",
    "# Convert DataFrame to array\n",
    "print(len(df_casualties_coords))\n",
    "casuality_array = df_casualties_coords.values\n",
    "\n",
    "# get the coordinates only\n",
    "X = np.array(casuality_array[:,4:6], dtype='int32')\n",
    "\n",
    "# Plot points for a visual checks\n",
    "sns.scatterplot(x=X[:,0], y=X[:,1])\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up DBSCAN\n",
    "\n",
    "Run multiple set of model fitting\n",
    "\n",
    "for accidents with 500k points it took approx ~ 12 minutes\n",
    "\n",
    "using only KSI (Killed and Seriously Injured Casuality), we have 131,355 points and it takes ~2min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get relative density accidents/sqm\n",
    "start_time=time()\n",
    "\n",
    "df_cluster_stats = pd.DataFrame(columns=['eps', 'min_samples', 'No of Clusters', 'Max Number of accidents', 'Max Density', 'Radius', 'Location_Easting_OSGR', 'Location_Northing_OSGR'])\n",
    "cnt=0\n",
    "\n",
    "for eps in range(5,71,5):\n",
    "    for min_sample in range(5,101,1):\n",
    "                \n",
    "        # Run DBSCAN\n",
    "        db = DBSCAN(eps=eps, min_samples=min_sample, n_jobs=12).fit(X)\n",
    "        labels = db.labels_\n",
    "        no_clusters = len(np.unique(labels))\n",
    "        \n",
    "        # Check if we have no Clusters\n",
    "        if no_clusters==1:\n",
    "            max_acc_no = np.nan\n",
    "            max_density = np.nan\n",
    "            coords = [np.nan, np.nan]\n",
    "        \n",
    "        else:\n",
    "            # merge cluster labels back\n",
    "            df_casualties_coords['Cluster No'] = labels\n",
    "            df_accidents_coords_complete_cluster = df_casualties_coords[df_casualties_coords['Cluster No']>(-1)].copy()\n",
    "    \n",
    "            max_acc_no = df_accidents_coords_complete_cluster['Cluster No'].value_counts().max()\n",
    "            max_clus_no = df_accidents_coords_complete_cluster['Cluster No'].value_counts().idxmax()\n",
    "            # get the centroid coordinates\n",
    "            df_cluster_centroid = df_accidents_coords_complete_cluster.groupby(by=['Cluster No'])[['Location_Easting_OSGR','Location_Northing_OSGR']].mean()\n",
    "    \n",
    "            # get estimated density using circle           \n",
    "            xy_max = df_accidents_coords_complete_cluster.groupby(by=['Cluster No'])[['Location_Easting_OSGR','Location_Northing_OSGR']].max()\n",
    "            xy_min = df_accidents_coords_complete_cluster.groupby(by=['Cluster No'])[['Location_Easting_OSGR','Location_Northing_OSGR']].min()\n",
    "            xy_delta = ((xy_max - xy_min)/2)**2\n",
    "            \n",
    "            # Populate centroid list DF\n",
    "            df_cluster_centroid['No of Accidents'] = df_accidents_coords_complete_cluster['Cluster No'].value_counts()\n",
    "            \n",
    "            # Increase the radius by eps/2 assuming conservatively a boundary\n",
    "            df_cluster_centroid['Radius'] = np.sqrt(xy_delta.sum(axis=1)) + eps/2\n",
    "            df_cluster_centroid['Area'] = np.pi * df_cluster_centroid['Radius']**2\n",
    "            df_cluster_centroid['Density'] = df_cluster_centroid['No of Accidents']/df_cluster_centroid['Area'] \n",
    "            df_cluster_centroid['eps'] = eps\n",
    "            df_cluster_centroid['min_samples'] = min_sample\n",
    "            \n",
    "            df_cluster_centroid.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            \n",
    "            # Cluster with max density\n",
    "            idx_max = df_cluster_centroid['Density'].idxmax()\n",
    "            max_density = df_cluster_centroid['Density'].max()\n",
    "            radius = df_cluster_centroid.loc[idx_max]['Radius']\n",
    "            \n",
    "            # Cordinates of Cluster\n",
    "            coords = df_cluster_centroid.values[idx_max]\n",
    "            \n",
    "        \n",
    "        # Populate output\n",
    "        df_cluster_stats.loc[cnt, :] = [eps, min_sample, no_clusters, max_acc_no, max_density,radius,coords[0],coords[1]]\n",
    "        if cnt==0:\n",
    "            df_cluster_list = df_cluster_centroid.copy()\n",
    "        else:\n",
    "            df_cluster_list = df_cluster_list.append(df_cluster_centroid)\n",
    "            \n",
    "        cnt+=1\n",
    "        \n",
    "elapsed_time = time() - start_time\n",
    "print('Clustering took: {:.2f} minutes'.format(elapsed_time/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_stats_clean = df_cluster_stats[df_cluster_stats['No of Clusters']>1]\n",
    "\n",
    "df_cluster_stats_clean.sort_values(by=['Max Number of accidents'], ascending=False)\n",
    "df_cluster_stats_clean.sort_values(by=['Max Density'], ascending=False).head(20)\n",
    "# df_cluster_stats_clean.sort_values(by=['Radius'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_list.sort_values(by='No of Accidents', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df_cluster_list['Location_Easting_OSGR'], y=df_cluster_list['Location_Northing_OSGR'])\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.relplot(x=\"Radius\", y=\"No of Accidents\", size='min_samples', sizes=(15, 200), data=df_cluster_list);\n",
    "\n",
    "sns.relplot(x=\"Radius\", y=\"eps\",\n",
    "            hue=\"No of Accidents\",\n",
    "#             size=\"Radius\",\n",
    "            sizes=(40, 400), alpha=.5, palette='mako_r',\n",
    "            height=6, data=df_cluster_list)\n",
    "\n",
    "# sns.relplot(x=\"eps\", y=\"Density\",\n",
    "# #             hue=\"eps\",\n",
    "# #             size=\"Density\",\n",
    "#             sizes=(40, 400), alpha=.5, palette='mako_r',\n",
    "#             height=6, data=df_cluster_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_list.sort_values(by='No of Accidents',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the location with highest point counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=50, min_samples=5, n_jobs=12).fit(X)\n",
    "labels = db.labels_\n",
    "df_casualties_coords['Cluster No'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents_to_check = df_casualties_coords[df_casualties_coords['Cluster No']==403]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents_to_check = df_accidents_to_check.merge(df_accidents[['Accident_Index','Latitude','Longitude']],\n",
    "                                                    on='Accident_Index', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents_to_check[['Location_Easting_OSGR', 'Location_Northing_OSGR']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(df_accidents_to_check, lat=\"Latitude\", lon=\"Longitude\",\n",
    "                        hover_name=\"Cluster No\",\n",
    "                        hover_data=[\"Accident_Severity\", \"Number_of_Casualties\",'Year'],\n",
    "                        color_discrete_sequence=[\"fuchsia\"], zoom=5, height=300)\n",
    "fig.update_layout(mapbox_style=\"carto-positron\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the location with highest density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_list.sort_values(by='Density',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=5, min_samples=13, n_jobs=12).fit(X)\n",
    "labels = db.labels_\n",
    "df_casualties_coords['Cluster No'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents_to_check = df_casualties_coords[df_casualties_coords['Cluster No']==3].copy()\n",
    "\n",
    "df_accidents_to_check = df_accidents_to_check.merge(df_accidents[['Accident_Index','Latitude','Longitude']],\n",
    "                                                    on='Accident_Index', how='left')\n",
    "\n",
    "df_accidents_to_check[['Location_Easting_OSGR', 'Location_Northing_OSGR']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(3)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_x = np.random.rand(len(df_accidents_to_check))/1000\n",
    "jitter_y = np.random.rand(len(df_accidents_to_check))/1000\n",
    "\n",
    "df_accidents_to_check[\"Latitude_x\"] = df_accidents_to_check[\"Latitude_x\"]+jitter_x\n",
    "df_accidents_to_check[\"Longitude_x\"] = df_accidents_to_check[\"Longitude_x\"]+jitter_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(df_accidents_to_check, lat=\"Latitude_x\", lon=\"Longitude_x\",\n",
    "                        hover_name=\"Cluster No\",\n",
    "                        hover_data=[\"Accident_Severity\", \"Number_of_Casualties\",'Year'],\n",
    "                        color_discrete_sequence=[\"fuchsia\"], zoom=5, height=300)\n",
    "fig.update_layout(mapbox_style=\"carto-positron\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_accident_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDTRee\n",
    "accident_tree = KDTree(accident_array[:,1:3])\n",
    "\n",
    "rank_cols = []\n",
    "\n",
    "for dist in range(50,215,15):\n",
    "    df_accidents_coords_complete.loc[:,'Neighbour ' + str(dist)+ 'm'] = accident_tree.query_radius(accident_array[:,1:3],\n",
    "                                                                                   r=dist,\n",
    "                                                                                   count_only=True)\n",
    "    \n",
    "    df_accidents_coords_complete.loc[:,'Neighbour ' + str(dist) + 'm rank'] = df_accidents_coords_complete.loc[:,'Neighbour ' + str(dist)+ 'm'].rank(ascending=False)\n",
    "    \n",
    "    rank_cols.append('Neighbour ' + str(dist) + 'm rank')\n",
    "#     df_accidents_coords_complete.sort_values(by='NeighbourNO', ascending=False).reset_index()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents_coords_complete['Av Rank'] = df_accidents_coords_complete[rank_cols].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents_coords_complete.sort_values(by=['Av Rank'], ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Optics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "optics_clustering = OPTICS(min_samples=40, max_eps=25, metric='euclidean', n_jobs=8).fit(X)\n",
    "\n",
    "end_time = time()\n",
    "print((end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optics_labels = optics_clustering.labels_\n",
    "print(len(np.unique(optics_labels)))\n",
    "\n",
    "df_accidents_coords_complete['OPTICS Cluster No'] = optics_labels\n",
    "\n",
    "df_accidents = df_accidents.merge(df_accidents_coords_complete[['Accident_Index', 'OPTICS Cluster No']],\n",
    "                                  left_on='Accident_Index', right_on='Accident_Index', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accident_clusters = df_accidents[df_accidents['OPTICS Cluster No_y']>-1].copy()\n",
    "len(df_accident_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(df_accident_clusters, lat=\"Latitude\", lon=\"Longitude\",\n",
    "                        hover_name='OPTICS Cluster No_y', hover_data=[\"Accident_Severity\", \"Number_of_Casualties\"],\n",
    "                        color_discrete_sequence=[\"fuchsia\"], zoom=5, height=300)\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we estimate the number of casualities and respective severity?\n",
    "\n",
    "A witness would know:\n",
    "- Location\n",
    "- type of Vehicles\n",
    "- Date/time\n",
    "- Surface conditions\n",
    "\n",
    "Out of those what would be relevant?\n",
    "\n",
    "What are we trying to estimate?\n",
    "<br>\n",
    "number of casualities with severity?\n",
    "get a single estimation with a vector of 3 elements: number of slight, serious, fatal\n",
    " - Multivariate Linear Regression\n",
    " - ## Let's use ANN\n",
    "\n",
    "- Veh Leaving Carriageway\n",
    "\n",
    "<br>get a model for each vehicle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_features = ['Accident_Index','Road_Type','Speed_limit','Junction_Detail','Junction_Control',\n",
    "                     'Light_Conditions','Weather_Conditions','Road_Surface_Conditions','Urban_or_Rural_Area']\n",
    "\n",
    "vehicle_features = ['Vehicle_Type']\n",
    "# Veh Leaving Carriageway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vehicle_classes = df_vehicles.groupby(['Accident_Index','Vehicle_Type']).size().unstack(fill_value=0)\n",
    "print(len(df_vehicle_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casaualty_severity = df_casualties.groupby(['Accident_Index','Casualty_Severity']).size().unstack(fill_value=0)\n",
    "casaualty_severity.rename(columns={1: \"Fatal\", 2: \"Serious\", 3: \"Slight\"}, inplace=True)\n",
    "casaualty_severity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_accidents[accident_features]))\n",
    "df_accidents_s1 = df_accidents[accident_features].merge(df_vehicle_classes, on=\"Accident_Index\")\n",
    "df_accidents_s2 = df_accidents_s1.merge(casaualty_severity, on=\"Accident_Index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply drop NA\n",
    "df_accidents_s3 = df_accidents_s2.drop(df_accidents_s2[df_accidents_s2.isnull().any(1)].index)\n",
    "\n",
    "# simply drop negatives:\n",
    "value_cols = ['Road_Type', 'Speed_limit', 'Junction_Detail', 'Junction_Control', 'Light_Conditions', 'Weather_Conditions', 'Road_Surface_Conditions',\n",
    " 'Urban_or_Rural_Area', -1, 1, 2, 3, 4, 5, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 90, 97, 98, 'Fatal',\n",
    " 'Serious', 'Slight']\n",
    "\n",
    "df_accidents_s3.loc[df_accidents_s3['Junction_Control']==-1, 'Junction_Control'] = 5\n",
    "df_accidents_s3.loc[df_accidents_s3['Junction_Detail']==-1, 'Junction_Detail'] = 10\n",
    "df_accidents_s3.loc[df_accidents_s3['Road_Surface_Conditions']==-1, 'Road_Surface_Conditions'] = 8\n",
    "\n",
    "df_accidents_s3.loc[df_accidents_s3['Light_Conditions']==-1, 'Light_Conditions'] = 8\n",
    "df_accidents_s3.loc[df_accidents_s3['Weather_Conditions']==-1, 'Weather_Conditions'] = 9\n",
    "\n",
    "df_accidents_s3.loc[df_accidents_s3['Road_Type']==-1, 'Road_Type'] = 9\n",
    "df_accidents_s3.loc[df_accidents_s3['Urban_or_Rural_Area']==-1, 'Urban_or_Rural_Area'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents_s3[(df_accidents_s3[value_cols] < 0).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cont_cols = ['Speed_limit', -1, 1, 2, 3, 4, 5, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 90, 97, 98]\n",
    "\n",
    "x_cat_cols = ['Road_Type', 'Junction_Detail', 'Junction_Control', 'Light_Conditions',\n",
    "              'Weather_Conditions', 'Road_Surface_Conditions', 'Urban_or_Rural_Area']\n",
    "\n",
    "label_cols = ['Fatal', 'Serious', 'Slight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(df_accidents_s3[x_cont_cols + x_cat_cols].values, dtype=torch.float)\n",
    "x_cont = torch.tensor(df_accidents_s3[x_cont_cols].values, dtype=torch.float)\n",
    "\n",
    "df_accidents_s3[x_cat_cols] = df_accidents_s3[x_cat_cols].astype(\"category\")\n",
    "x_cat = torch.tensor( np.stack( [df_accidents_s3[col].cat.codes.values for col in x_cat_cols], axis=1), dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(df_accidents_s3[label_cols].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Danger:</b> \n",
    "\n",
    "ADD SHUFFLING\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train = x_cat[:batch_size-test_size]\n",
    "cat_test = x_cat[batch_size-test_size:batch_size]\n",
    "con_train = x_cont[:batch_size-test_size]\n",
    "con_test = x_cont[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.35):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        \n",
    "        # normalise the continous data\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum([nf for ni,nf in emb_szs])\n",
    "        n_in = n_emb + n_cont\n",
    "        \n",
    "        # Create list of fully connected layers\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i))\n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        \n",
    "        # fully connected layer\n",
    "        layerlist.append(nn.Linear(layers[-1], out_sz))\n",
    "        \n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "        \n",
    "        \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        \n",
    "        embeddings = []\n",
    "                \n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        # Concatenate individial vectors of categorical columns from embeddings    \n",
    "        x = torch.cat(embeddings, 1)\n",
    "        # Apply dropout\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        # Normalise continous data\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        \n",
    "        # Concatenate categorical and continous columns\n",
    "        x = torch.cat([x,x_cont],1)\n",
    "        # Pass through tensor the fully connected layers\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = RegressionModel(emb_szs, len(x_cont_cols), 3, [200,100,60], p=0.4)\n",
    "\n",
    "criterion = nn.MSELoss() # np.sqrt(MSE) --> RMS\n",
    "\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "batch_size = 60000\n",
    "test_size = int(batch_size * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    \n",
    "    y_pred = model(cat_train,con_train)\n",
    "    y_pred = torch.round(y_pred)\n",
    "    loss = torch.sqrt(criterion(y_pred, y_train))\n",
    "    \n",
    "    losses.append(loss)\n",
    "    \n",
    "    if i%10 == 1:\n",
    "        print(f'epoch: {i} loss is {loss}')\n",
    "        \n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "end_time = time()\n",
    "duration = end_time - start_time\n",
    "print(f'Traning took {duration/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    y_val = model(cat_test,con_test)\n",
    "    \n",
    "    loss = torch.sqrt(criterion(y_val, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    \n",
    "    print(f'{i}.) Predicted: {y_val[i]} TRUE: {y_test[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
